# -*- coding: utf-8 -*-
"""Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14pMVTQK7RaWbT7VMhj7Qnk2L-6tawb_X

# **Bankruptcy Prediction with Machine Learning Models**

**Χαμαλίδης Βασίλειος-Σωτήριος**


Πανεπιστήμιο Μακεδονίας - Πληροφοριακά Συστήματα

Μάθημα επιλογής Μηχανική Μάθηση 7o εξ.

*Πρώτη εργασία Classification*

ΘΕΣΣΑΛΟΝΙΚΗ 2024

# Data importing
"""

# Import libraries for data processing and visualization
import pandas as pd  # For data manipulation and analysis using DataFrames
import matplotlib.pyplot as plt  # For creating plots and visualizations
import seaborn as sns  # For advanced and aesthetically pleasing visualizations
import numpy as np  # For numerical operations and array handling

# Libraries for file handling, time measurement, and preprocessing
import csv  # To read and write CSV files
import time  # To measure execution time
import os  # For interacting with the operating system (e.g., file paths)

# Scikit-learn libraries for preprocessing and model evaluation
from sklearn.preprocessing import MinMaxScaler  # For scaling data to a given range
from sklearn.model_selection import StratifiedKFold  # For stratified k-fold cross-validation

# Pandas utility for visualizing scatter plots of features
from pandas.plotting import scatter_matrix  # For scatter plot matrices of numerical features

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Upload Dataset Function
def upload_dataset():
    data_upload = files.upload()
    filename = list(data_upload.keys())[0]
    filename = re.sub(".xlsx", "", filename)
    return filename

!pip install openpyxl
import openpyxl

# Load Data2Use
## 1. Να διαβάζει τα δεδομένα από το αρχείο excel.
fileNameFullPath = '/content/drive/MyDrive/??/??.xlsx'

# In case the file is not found then open the Open File Dialog
if not os.path.exists(fileNameFullPath):
  fileNameFullPath = upload_dataset()

df = pd.read_excel(fileNameFullPath)

"""# Data Preprocessing"""

# Rename columns from Greek to Latin
renamed_col = {
    '365* ( Β.Υ / Κοστ.Πωλ )': 'NDays_recover_inv',
    'Λειτ.Αποτ/Συν.Ενεργ. (ROA)': 'ROA',
    'ΧΡΗΜ.ΔΑΠΑΝΕΣ / ΠΩΛΗΣΕΙΣ': 'Cash_Expense_Ratio',
    ' ΠΡΑΓΜΑΤΙΚΗ ΡΕΥΣΤΟΤΗΤΑ :  (ΚΕ-ΑΠΟΘΕΜΑΤΑ) / Β.Υ': 'Quick_Ratio',
    '(ΑΠΑΙΤ.*365) / ΠΩΛ.': 'DSO',
    'Συν.Υποχρ/Συν.Ενεργ':'Debt_to_Assets_ratio',
    'Διάρκεια Παραμονής Αποθεμάτων':'Inventory_turnover',
    'Λογαριθμος Προσωπικού':'Staff_Logarithm',
    'ΕΝΔΕΙΞΗ ΕΞΑΓΩΓΩΝ': 'Export_Indicator',
    'ΕΝΔΕΙΞΗ ΕΙΣΑΓΩΓΩΝ': 'Import_Indicator',
    'ΕΝΔΕΙΞΗ ΑΝΤΙΠΡΟΣΩΠΕΙΩΝ': 'Representation_Indicator',
    'ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)': 'Inconsistency_Indicator',
    'ΕΤΟΣ': 'Year'
}

# Create a reverse mapping (for searching Greek names from the new English names)
col_Gr = {v: k for k, v in renamed_col.items()}

# Rename the columns in the DataFrame
df.rename(columns=renamed_col, inplace=True)

# Display the updated column names
print(df.columns)

# Test: Retrieve the original Greek column name for 'Debt_to_Assets_ratio'
print("\n" + col_Gr.get('Debt_to_Assets_ratio'))

"""## Data Visualization"""

## Plot: Number of Healthy vs Bankrupt Firms by Year

# Group data by 'Year' and 'Inconsistency_Indicator', counting occurrences
grouped = df.groupby(['Year', 'Inconsistency_Indicator']).size().unstack(fill_value=0)

# Create the bar plot with side-by-side bars (stacked=False)
ax = grouped.plot(kind='bar', stacked=False, figsize=(10, 6), color=['skyblue', 'salmon'])

# Set the title and axis labels
plt.title('Bankrupt vs Trustworthy Firms by Year')
plt.xlabel('Year')
plt.ylabel('Number of Firms')
plt.legend(['Trustworthy', 'Bankrupt'], title='Status')  # Label for the legend
plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability

# Add the count values on top of each bar for clarity
for container in ax.containers:
    ax.bar_label(container, label_type='edge')  # 'edge' places labels above the bars

# Adjust layout to ensure everything fits
plt.tight_layout()

# Show the plot
plt.show()

'''b. Figure 2: Την min, max, average τιμή για κάθε δείκτη. Προσοχή: εδώ θα έχετε 2
subfigures. Ένα θα έχει τις τιμές υγειών εταιρειών και ένα διαφορετικό τις τιμές για τις
πτωχευμένες.'''

colors = ['#1f77b4', '#d62728']

for col_index in range(0, len(df.columns) -5): # Ignore Year and Indicators
    plt.figure(figsize=(10,8))

    sns.set(style="whitegrid")
    # Compare with the 'Inconsistency_Indicator' (= df.columns[len(df.columns) -2] = 11)
    sns.boxplot(x=df.columns[len(df.columns) -2], y=df.columns[col_index], data=df, hue=df.columns[len(df.columns) - 2], palette=colors, legend=False)

    # Show the original (Greek) title
    plt.title(f'Column {col_index+1} - {col_Gr.get(df.columns[col_index])}')
    plt.xlabel('Class')
    plt.ylabel('Values')

    # Replace numeric ticks with corresponding labels
    plt.xticks(ticks=[0, 1], labels=['Trustworthy', 'Bankrupted'])

    print(f"\nPloting: {df.columns[col_index]}")
    plt.show()

df = df.drop(columns=['DSO','Quick_Ratio', 'Inventory_turnover' ], axis=1).copy()

"""## Data Validation"""

## 3. Να ελέγχει για τυχόν ελλείπεις εγγραφές [π.χ. NaNs] και να ειδοποιεί τον χρήστη με σχετικό μήνυμα.

def nan_report(df):
    # Count the number of NaN values in each column
    nan_count = df.isna().sum()

    # Calculate the percentage of NaN values in each column, rounded to 2 decimal places
    nan_percentage = (df.isna().mean() * 100).round(2)

    # Combine count and percentage into a single DataFrame for easier interpretation
    report = pd.DataFrame({
        'NaN Count': nan_count,
        'NaN Percentage': nan_percentage
    })

    # Print the combined NaN report
    print("Combined NaN Report:")
    print(report)

    # Check if there are any missing values and provide appropriate feedback
    if report['NaN Count'].max() == 0:
        print("\nThere are no missing values in the DataFrame.")
    else:
        print("\nYour DataFrame contains missing values.")

# Show the NaN report
nan_report(df)

# verification of null values
df.info()

# The 'Inconsistency_Indicator' column values are being reversed.
# Companies with '1' (indicating trustworthy) will be converted to 0 (healthy),
# and companies with '2' (indicating bankrupt) will be converted to 1 (bankrupt).
df['Inconsistency_Indicator'] = df['Inconsistency_Indicator'].replace({1: 0, 2: 1})

"""## Data Scaling

ΕΡΩΤΗΜΑ: " 4. Να κανονικοποιεί τα δεδομένα στο διάστημα [0,1] με χρήση τεχνικής τύπου map minmax. "

Η κανονικοποίηση θα γίνει ξεχωριστά για κάθε ένα fold για να μην δημιουργηθεί data leakage μεταξύ τους.

Για ένα fold θα γίνεται ξεχωριστά το σύνολο εκπαίδευσης και εξέτασης.

 " *Global Scaling: Applying scaling based on the entire dataset, including the test set, instead of just the training set, introduces information from the test set.* "

https://shelf.io/blog/preventing-data-leakage-in-machine-learning-models/

https://machinelearningmastery.com/data-preparation-without-data-leakage/

https://www.ibm.com/think/topics/data-leakage-machine-learning

https://airbyte.com/data-engineering-resources/what-is-data-leakage#:~:text=Data%20leakage%20in%20machine%20learning%20occurs%20when%20information%20from%20outside,in%20unreliable%20and%20inaccurate%20predictions.
"""

# scaler = MinMaxScaler()
# # Avoid norm 4 last columns, keep labels intact
norm_col = ['NDays_recover_inv', 'ROA', 'Cash_Expense_Ratio', 'Quick_Ratio', 'DSO',
       'Debt_to_Assets_ratio', 'Inventory_turnover', 'Staff_Logarithm', 'Year']

def scaler(data):
  # Initialize the MinMaxScaler to scale the data
  scalermm = MinMaxScaler()
  # Scale only the columns in 'norm_col' and keep the other columns unchanged
  data_scaled = data.copy()  # Create a copy of the data to preserve the original structure
  data_scaled = scalermm.fit_transform(data)  # Apply MinMax scaling to 'norm_col'
  return data_scaled  # Return the scaled DataFrame

"""## Cross Validation"""

## 5. Να κάνει χρήση του Stratified kfold ώστε να δημιουργεί 4 folds.

# Predictors
X = df.drop(columns=['Inconsistency_Indicator'], axis=1)

# Response var
y = df['Inconsistency_Indicator']

# Create a StratifiedKFold instance with 4 folds
skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)

# Generate the splits
splits = skf.split(X, y)

'''6. Να τυπώνει στην οθόνη, για κάθε fold, πόσες χρεωκοπημένες και πόσες υγιείς εταιρείες
υπάρχουν στο a) train και στο b) test set.'''

print("Trustworthy : 0 , Bankrupt : 1")
# to_dictionary() to avoid printing 'dtype: int64' at the end of the line
for i, (train_index, test_index) in enumerate(skf.split(X, y)):
    print(f"Fold {i}:")
    print(f"  Train: \n{df['Inconsistency_Indicator'][train_index].value_counts().to_dict()}")
    print(f"  Test:  \n{df['Inconsistency_Indicator'][test_index].value_counts().to_dict()}")

"""## Class Imbalance"""

'''7. Αν η κατανομή είναι πάνω από 3 υγιείς επιχειρήσεις για κάθε χρεωκοπημένη, διαλέξτε με
τυχαίο τρόπο όσες υγιείς εταιρείες χρειαστεί, ώστε η αναλογία στο training set να είναι 3 υγιείς
/ 1 χρεωκοπημένη'''

# This is the target ration
target_ratio = 3

# Let's view how bad the class impalance is
# Create a new column for the rate class imbalance
grouped['Class distribution'] = ((grouped[1] / grouped[2])).round(2)

# Number that need to be removed
grouped['Total remove of Trustwthy'] = np.where(grouped[1] > grouped[2],\
 grouped[1] - grouped[2]*target_ratio, 0)

# show the results
print(grouped)

print("\nIn total:")

# Count distictive values on Inconsistency_Indicator
bankr_count = df['Inconsistency_Indicator'].value_counts()

# Compine into a single DF
class_distribution = pd.DataFrame(\
 {'Trustworthy': [bankr_count[0]], \
  'Bankrupted': [bankr_count[1]], \
  'Class Distribution Ratio': [(bankr_count[0]/bankr_count[1]).round(2)]})

print(str(class_distribution))

if class_distribution['Class Distribution Ratio'][0] > target_ratio:
  print("\nSevere Class Imbalance!")
else:
  print("\nNo Class Imbalance")

# Show pie diagram of the majority class
plt.pie(df['Inconsistency_Indicator'].value_counts(), labels=['Trustworthy', 'Bankrupted'], autopct='%1.1f%%', startangle=90)
plt.title('Class Distribution')
plt.show()

"""### Majority class Reduction

"""

# Function to return a balanced training set
def balance_TrainSet(train_index, ratio=target_ratio):
    # List to store the indices of the balanced training set
    balanced_train_indices = []

    # Filter the original DataFrame using the provided train_index
    train_df = df.iloc[train_index]

    # Separate the DataFrame into healthy (trustworthy) and bankrupt companies
    trustwrth = train_df[train_df['Inconsistency_Indicator'] == 0]
    bankruptd = train_df[train_df['Inconsistency_Indicator'] == 1]

    # Calculate how many healthy companies need to be sampled to achieve the desired ratio
    excess_count = len(trustwrth) - ratio * len(bankruptd)

    if excess_count > 0:
        # If the majority class (healthy) exceeds the target ratio, sample the appropriate number
        sampled_trustwrth = trustwrth.sample(n=int(ratio * len(bankruptd)), random_state=64)
        # Add the sampled indices to the balanced set
        balanced_train_indices.extend(sampled_trustwrth.index)
        balanced_train_indices.extend(bankruptd.index)
    else:
        # If there is no imbalance, keep all the rows as they are
        balanced_train_indices.extend(trustwrth.index)
        balanced_train_indices.extend(bankruptd.index)

    # Convert the list of indices to a numpy array
    balanced_train_indices = np.array(balanced_train_indices)

    return balanced_train_indices

# Display how the train folds are balanced
for i, (train_index, test_index) in enumerate(skf.split(X, y)):
    print(f"Fold {i + 1}:")
    # Get the balanced train set of ration 3
    balanced_train_indices = balance_TrainSet(train_index)

    # Display class balance
    print("Training class distribution:", y[balanced_train_indices].value_counts().to_dict())
    print("Test class distribution:", y[test_index].value_counts().to_dict())

"""# ML Training"""

# Import necessary ML models and performance metrics

# a) Linear Discriminant Analysis (LDA)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# b) Logistic Regression
from sklearn.linear_model import LogisticRegression

# c) Decision Trees
from sklearn.tree import DecisionTreeClassifier

# d) Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

# e) k-Nearest Neighbors (KNN)
from sklearn.neighbors import KNeighborsClassifier

# f) Naïve Bayes (Gaussian Naive Bayes)
from sklearn.naive_bayes import GaussianNB

# g) Support Vector Machines (SVM)
from sklearn.svm import SVC

# h) Gradient Boosting Classifier (Personal Choice)
from sklearn.ensemble import GradientBoostingClassifier

# Performance metrics for model evaluation
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report

"""## File configuration for output saving"""

# Create folder path
# Specify the Drive Path
drive_path = '/content/drive/MyDrive/ML_COLAB/ERG1/out'

# Check if the folder 'MyDrive/ML_COLAB/Classification_problems/out' exists, and create it if necessary
if not os.path.exists(drive_path):
    os.makedirs(drive_path)

# Check if the folder 'img' exists, and create it if necessary
figure_folder_path = os.path.join(drive_path, 'img')
if not os.path.exists(figure_folder_path):
    os.makedirs(figure_folder_path)

"""## Confusion Matrix"""

# Function to create and save a customized confusion matrix plot
def funcy_cf_plot(cf_matrix, class_names, fullMatrixName, directoryToSave, typeD):
    # 'cf_matrix': Confusion matrix (2x2 array)
    # 'class_names': List of class names (e.g., ['Trustworthy', 'Bankrupt'])
    # 'fullMatrixName': Full name for saving the matrix image (e.g., 'cf_matrix.png')
    # 'directoryToSave': Directory path to save the matrix image
    # 'typeD': Title for the heatmap

    # Format the count values with no decimals
    group_counts = ["{0:0.0f}".format(value) for value in cf_matrix.flatten()]

    # Format the percentage values with two decimals
    group_percentages = ["{0:.2%}".format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]

    # Combine count and percentage for labels
    labels = [f"{v1}\n{v2}\n" for v1, v2 in zip(group_counts, group_percentages)]

    # Reshape the labels to fit the 2x2 confusion matrix
    labels = np.asarray(labels).reshape(2, 2)

    # Create the heatmap with the confusion matrix values and formatted labels
    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')

    # Set the title and axis labels
    ax.set_title(typeD)
    ax.set_xlabel('Predicted company status')
    ax.set_ylabel('Actual company status')

    # Set the tick labels for both axes based on class names
    ax.xaxis.set_ticklabels(class_names)
    ax.yaxis.set_ticklabels(class_names)

    # Save the heatmap figure to the specified directory
    figure_path = os.path.join(directoryToSave, fullMatrixName)
    plt.savefig(figure_path)

    # Display the confusion matrix plot
    plt.show()

"""## Simulation Function"""

# Create a list to store the data
csv_data = []
# Append header row
csv_data.append(["Classifier Name", "Training or test set", "FoldId",\
                 "Balanced or unbalanced train set", \
                 "Number of training samples", \
                 "Number of non-healthy companies in training sample",\
                 "TP", "TN", "FP", "FN",\
                 "ROC-AUC"\
                 ])

def one_model_sim_function(modelName, clf, inputData, outputData,\
                           train_index, test_index,\
                           figure_folder_path, foldNum):

  # Split the data into training and validation sets
  X_train, X_val = inputData.iloc[train_index], inputData.iloc[test_index]
  y_train, y_val = outputData.iloc[train_index], outputData.iloc[test_index]

  ## 4. Να κανονικοποιεί τα δεδομένα στο διάστημα [0,1] με χρήση τεχνικής τύπου map minmax.
  # Initialize a MinMaxScaler and fit on the training data only
  X_train_scaled = scaler(X_train)

  # For validation data
  X_val_scaled = scaler(X_val)

  print(f'\n = = = Working with classifier {modelName} = = = ')

  # Εμφάνιση της κατανομής των κλάσεων
  print("Training class distribution:", y[train_index].value_counts().to_dict())
  print("Test class distribution:", y[test_index].value_counts().to_dict())

  #train the classifier
  start_time = time.time() # Record start time
  clf.fit(X_train_scaled, y_train)
  end_time = time.time() # Record end time

  trainingTime = end_time - start_time
  print('. just finished with training in {:.4f} seconds'.format(trainingTime))

  #use the trained classifier to estimate the outputs

  start_time = time.time() # Record start time
  predicted_output_values_train =\
   clf.predict(X_train_scaled)
  end_time = time.time() # Record end time

  predTimeTrain = end_time - start_time

  start_time = time.time() # Record start time
  predicted_output_values_test =\
   clf.predict(X_val_scaled)
  end_time = time.time() # Record end time

  predTimeTest = end_time - start_time

    #confusion matrices here
  cf_matrix_train = confusion_matrix(y_train,\
                                  predicted_output_values_train )

  cf_matrix_test = confusion_matrix(y_val,\
                                predicted_output_values_test )

  #create some figures with confusion matrices
  funcy_cf_plot(cf_matrix_train, ['Trustworthy','Bankrunpted'],\
                modelName + str(foldCounter) + "balanced" + "Train",\
                figure_folder_path, 'Train set ' + modelName + ' F:' + str(foldCounter))
  funcy_cf_plot(cf_matrix_test, ['Trustworthy','Bankrunpted'],\
                modelName + str(foldCounter) + "unbalanced" + "Test",\
                figure_folder_path, 'Test set ' + modelName + ' F:' + str(foldCounter))

  # Print the prediction scores for train and validation set
  print(f"\nScores for Train set for {modelName}")
  print(f">Accuracy: \t{accuracy_score(y_train, predicted_output_values_train):.2f}")
  print(f">Precision: \t{precision_score(y_train, predicted_output_values_train):.2f}")
  print(f">Recall: \t{recall_score(y_train, predicted_output_values_train):.2f}")
  print(f">f1:     \t{f1_score(y_train, predicted_output_values_train):.2f}")
  print(f">ROC AUC: \t{roc_auc_score(y_train, predicted_output_values_train):.2f}")

  print("Scores for Validation set")
  print(f">Accuracy: \t{accuracy_score(y_val, predicted_output_values_test):.2f}")
  print(f">Precision: \t{precision_score(y_val, predicted_output_values_test):.2f}")
  print(f">Recall: \t{recall_score(y_val, predicted_output_values_test):.2f}")
  print(f">f1:     \t{f1_score(y_val, predicted_output_values_test):.2f}")
  print(f">ROC AUC: \t{roc_auc_score(y_val, predicted_output_values_test):.2f}\n")

  print('. just finished with saving the confusion matrices.')

  #add line for train data
  tmp_csv_line_to_append = [modelName, "Train", foldCounter,  "balanced",\
                            len(y_train), \
                            sum(y_train==1),\
                            cf_matrix_train[1,1], cf_matrix_train[0,0], cf_matrix_train[0,1],cf_matrix_train[1,0],\
                            roc_auc_score(y_train, predicted_output_values_train)]

  csv_data.append(tmp_csv_line_to_append)
  #add line for test data
  tmp_csv_line_to_append = [modelName, "Test", foldCounter, "unbalanced",\
                            len(y_val), sum(y_val==1),\
                            cf_matrix_test[1,1], cf_matrix_test[0,0], cf_matrix_test[0,1],cf_matrix_test[1,0],\
                            roc_auc_score(y_val, predicted_output_values_test)]

  csv_data.append(tmp_csv_line_to_append)
  print('. just finished with data append to csv file.\n\n')

"""## Model training and Confution Matrix"""

# Run every model for each fold
foldCounter = 1

for train_index, test_index in skf.split(X, y):

  print('Fold number: ', str(foldCounter))

  # Get the balanced set
  balanced_train_indices = balance_TrainSet(train_index)

  # SVM
  one_model_sim_function("SVM", SVC(), X, y,\
                         balanced_train_indices, test_index,\
                         figure_folder_path, foldCounter)

  #Ctree
  one_model_sim_function("Ctree", DecisionTreeClassifier(), X, y,\
                           balanced_train_indices, test_index,\
                          figure_folder_path, foldCounter)

  #LDA
  one_model_sim_function("LDA", LinearDiscriminantAnalysis(), X, y,\
                           balanced_train_indices, test_index,\
                          figure_folder_path, foldCounter)

  #LR
  one_model_sim_function("LR", LogisticRegression(), X, y,\
                           balanced_train_indices, test_index,\
                          figure_folder_path, foldCounter)

  #RF
  one_model_sim_function("RF", RandomForestClassifier(), X, y,\
                           balanced_train_indices, test_index,\
                          figure_folder_path, foldCounter)

  #kNN
  one_model_sim_function("kNN", KNeighborsClassifier(), X, y,\
                          balanced_train_indices, test_index,\
                        figure_folder_path, foldCounter)

  #NB
  one_model_sim_function("NB", GaussianNB(), X, y,\
                          balanced_train_indices, test_index,\
                        figure_folder_path, foldCounter)
  #BG
  one_model_sim_function("GB", GradientBoostingClassifier(), X, y,\
                          balanced_train_indices, test_index,\
                        figure_folder_path, foldCounter)

  #update the fold counter
  foldCounter +=1;

from IPython.display import display

# Save the results to Data Frame
balncedDataOut_df = pd.DataFrame.from_dict(csv_data)
# Write result to Google drive
balncedDataOut_df.to_csv(drive_path + '/balncedDataOut_df.csv')
print(". results saved to Google Drive")
display(balncedDataOut_df)